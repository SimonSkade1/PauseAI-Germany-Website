name,text
Anrdrzej J. Buras,"Mit KI erschaffen wir eine neue intelligente Spezies, und wir tun dies häufig nicht mit der nötigen Sorgfalt, sondern in einem Wettlauf darum, wer es am schnellsten schafft. KI bietet viele Möglichkeiten, aber ohne internationale Sicherheitsstandards riskieren wir, von intellektuell überlegenen KIs verdrängt zu werden."
Peter Hubwieser,"Ich habe Informatik-Bildung in Bayern maßgeblich mitgestaltet. Die nächste Generation wird mit KI-Systemen aufwachsen, deren Möglichkeiten und Risiken wir selbst noch nicht überblicken. Verbindliche Sicherheitsregeln sind auch eine Frage der Verantwortung gegenüber jungen Menschen."
Peter Scholze,"Bereits jetzt halte ich den Einfluss von KI für stark negativ: Auf die Menschheit, auf die Demokratie, auf den Planeten."
Dieter Birnbacher,"Sicherheit vor katastrophalen Entgleisungen ist ein menschliches Grundbedürfnis. Ein internationales Abkommen mit klaren Grenzziehungen wäre ein erster Schritt zu einer vertrauenswürdigen KI."
Sven Apel,"Als Forscher im Bereich Software Engineering weiß ich, wie schwer es ist, die Zuverlässigkeit komplexer Softwaresysteme sicherzustellen. Bei KI-Systemen, die ihr Verhalten selbst erlernen, ist diese Herausforderung um Größenordnungen schwieriger. Ohne verbindliche Prüfstandards fliegen wir im Blindflug."
Jan Siemens,"Bevor ein neues Medikament auf den Markt kommt und  Menschen verabreichte werden darf durchläuft es ausführliche Sicherheitsprüfungen. Bei KI-Systemen, die auch tief in unser Leben eingreifen können, gibt es keinen vergleichbaren Prozess. Dieses Missverhältnis verlangt nach Korrektur."
Lutz Prechelt,"Im Software Engineering ist es eine Binsenweisheit, dass die Sorgfalt bei der Qualitätssicherung zu dem Risiko passen muss, das ein System erzeugt. Bei der KI agiert die Welt stattdessen nach der Devise „Wird schon nichts passieren!“. Der EU AI Act ist ein guter Anfang – in Europa; wir brauchen etwas Ähnliches dringend weltweit."
Mandy Jeske,"In der Molekularbiologie und Biochemie sehen und nutzen wir bereits das enorme Potenzial von KI für die Forschung. Gleichzeitig warnen führende KI-Unternehmen selbst davor, dass ihre Systeme den Missbrauch biologischen Wissens erleichtern könnten. Das verlangt dringend nach verbindlichen Schutzmaßnahmen."
Manfred Loimeier,"Neue Technologien bergen stets Chancen und Risiken. Künstliche Intelligenz bietet ungeahnte Potenziale. Genau deshalb sind Richtlinien erforderlich, und genau dies betonen Wissenschaftler aller Fachbereiche bereits seit etlichen Jahren. Es wird Zeit, dass ihre Stimme in der Politik endlich zu Konsequenzen führt."
Otmar Venjakob,"Als Dekan für Mathematik und Informatik habe ich die Begeisterung über KI-Fortschritte jeden Tag erlebt. Nicht zuletzt durch die intensive Auseinandersetzung im Rahmen unserer Vortragsreihe 'KI und Ethik' habe ich aber auch eine Vielzahl offener Sicherheitsbedenken und ethischer Fragestellungen erkannt, die mit jedem Fähigkeitssprung drängender werden. Ein internationaler Ordnungsrahmen ist daher längst überfällig."""
Matthias Bartelmann,"Menschliches Denken und künstliche Intelligenz sind grundlegend verschieden. Bevor wir diese Unterschiede nicht verstehen, wissen wir nicht, wohin sich die KI selbst entwickeln wird. Mit ihr füttern wir einen Drachen, dessen langfristiges Verhalten wir nicht einschätzen können."
Peter Kirsch,"Menschen mit psychischen Problemen suchen immer häufiger nach Beratung und Unterstützung durch KI-Systeme, die mit ihnen wie ein Psychotherapeut / eine Psychotherapeutin interagieren. Gerade in schwierigen Lebenslagen sind wir Menschen anfällig für Beeinflussung. Deswegen benötigen wir klare und verbindliche Regeln für die Anwendung von solchen Systemen auch im Bereich der Klinischen Psychologie und Psychotherapie."
Michael Zech,"Als Umweltwissenschaftler sehe ich Parallelen zwischen dem Klimawandel und der KI-Entwicklung: Beide sind globale Risiken, bei denen frühes Handeln ungleich wirksamer ist als späte Schadensbegrenzung. Internationale Sicherheitsstandards für KI sind eine Frage der Vorsorge."
Peter Knippertz,"In der Klimaforschung erleben wir, was passiert, wenn systemische Risiken zu lange ignoriert werden. Auch bei der KI-Entwicklung gibt es klare Warnungen und auch hier fehlt bisher der politische Wille zum konsequenten Handeln."
Joachim Funke,"Mein Forschungsgebiet ist das komplexe Problemlösen und Denken beim Menschen. KI-Systeme „denken“ inzwischen für uns und lösen zunehmend Probleme, die wir ihnen nicht explizit beigebracht haben. Diese Entwicklung ist beeindruckend und zugleich beunruhigend, denn wir haben keine zuverlässige Methode, die Eigenständigkeit dieser Systeme einzugrenzen."
Kerstin Göpfrich,"Sprachmodelle (LLMs) zum Design von synthetischen Genomen haben großes Potential. Um das Potential verantwortungsvoll nutzen zu können, braucht es weitsichtige Regeln."
Wolfram Barfuss,"Meine Forschung zeigt, wie schwierig es ist, kollektive Übergänge zu nachhaltigen Systemen zu gestalten. Bei KI stehen wir vor einer ähnlichen Herausforderung: Ohne kluge internationale Regeln werden kurzfristige Wettbewerbsinteressen langfristige Sicherheit verdrängen."
Hiltrud Kier,"Auch neue Errungenschaften brauchen Regeln, um für die Allgemeinheit nicht zur Belastung zu werden."